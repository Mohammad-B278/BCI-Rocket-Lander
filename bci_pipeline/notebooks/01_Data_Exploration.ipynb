{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13807893-cd2c-476e-881b-ec01a80d5bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from mne.datasets import eegbci\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from mne.decoding import CSP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f4339c-a309-42d8-b702-1ca18b5af880",
   "metadata": {},
   "source": [
    "### 1. Setup and Configuration\n",
    "\n",
    "This section defines the parameters for our analysis. We specify the subject ID and the corresponding experimental run numbers for the different motor imagery tasks as detailed on the PhysioNet dataset description page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b16dee61-e0ce-4e12-8c3b-f995008b00a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id = 1\n",
    "runs_lr = [4, 8, 12] # right or left hand fists data\n",
    "runs_feet = [6, 10, 14] # feet or both fists data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b30270-f06d-44b2-8c14-d855677ce335",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "Here, we use the `mne.datasets.eegbci.load_data` function to automatically download the required `.edf` files from the public PhysioNet repository. We are downloading two distinct sets of experiments: one for left vs. right hand imagery and another that includes feet imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "808cc5f7-cf6e-4a30-93c8-f859815e6b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data...\n",
      "Download complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"Downloading data...\")\n",
    "fnames_lr = eegbci.load_data(subject_id, runs = runs_lr, update_path = True)\n",
    "print(\"Download complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89de5ff1-12c1-47a5-858d-b8afb5e041df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data...\n",
      "Download complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"Downloading data...\")\n",
    "fnames_feet = eegbci.load_data(subject_id, runs = runs_feet, update_path = True)\n",
    "print(\"Download complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2abc4ce-f4df-4fdc-8930-af74061fb9ee",
   "metadata": {},
   "source": [
    "## 3. Reading and Combining Raw Data\n",
    "\n",
    "The downloaded `.edf` files are loaded into MNE's core data structure, the `Raw` object. Since each task (e.g., left/right fist) consists of multiple recording sessions (runs), we concatenate them to create a single, continuous data stream for each task type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4100968-6923-4b7c-944f-a98be9c02340",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /Users/Mohammad/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R04.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /Users/Mohammad/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R08.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /Users/Mohammad/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R12.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n"
     ]
    }
   ],
   "source": [
    "raws_lr = [mne.io.read_raw_edf(f, preload = True) for f in fnames_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18410d3f-f82a-4812-89e9-c834ab31a82c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /Users/Mohammad/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R06.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /Users/Mohammad/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R10.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /Users/Mohammad/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R14.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n"
     ]
    }
   ],
   "source": [
    "raws_feet = [mne.io.read_raw_edf(f, preload = True) for f in fnames_feet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdaa1d19-e9b2-42ad-8d5c-0651d616d555",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate the list of Raw objects for each task into a single, continuous Raw object.\n",
    "raw_lr = mne.concatenate_raws(raws_lr)\n",
    "raw_feet = mne.concatenate_raws(raws_feet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f228e9-97d5-420e-8ca9-75215c7ce3ad",
   "metadata": {},
   "source": [
    "## 4. Signal Preprocessing and Epoching\n",
    "\n",
    "This is the most critical data cleaning and preparation stage.\n",
    "\n",
    "### Signal Filtering\n",
    "Raw EEG data is noisy. We apply two main filters:\n",
    "1.  **Band-Pass Filter (8-35 Hz):** We isolate the frequency bands most associated with motor control and imagery, known as the *mu* (μ) and *beta* (β) rhythms. This removes slow signal drifts and high-frequency noise.\n",
    "2.  **Notch Filter (50 Hz):** This specifically targets and removes electrical noise from the power grid, which is a common and powerful source of interference.\n",
    "\n",
    "### Epoching\n",
    "We slice the continuous signal into discrete time windows called **epochs** or **trials**. Each epoch is locked to a specific event (e.g., the cue to imagine moving the left fist). By creating these labeled trials, we transform the data into a format suitable for supervised machine learning. We use a time window from -1s to +4s to also capture the brain's preparatory activity before the cue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf405a05-9cf0-4cbc-b7b6-90d2fddc5576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_epoch(raw, event_id):\n",
    "    raw.filter(l_freq=8., h_freq=35.)\n",
    "    raw.notch_filter(freqs=50)\n",
    "    \n",
    "    # Extract events from annotations. 'T1' and 'T2' are markers in the data\n",
    "    # corresponding to the start of different tasks.\n",
    "    events, _ = mne.events_from_annotations(raw, event_id={'T1': 1, 'T2': 2})\n",
    "\n",
    "    # starting 1 second before the cue to capture preparatory brain activity.\n",
    "    epochs = mne.Epochs(raw, events, event_id, tmin=-1., tmax=4., preload=True, baseline=None, picks='eeg')\n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e1a50e4-73ba-4426-9311-47c88c54f3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 3 contiguous segments\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "Filtering raw data in 3 contiguous segments\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 1057 samples (6.606 s)\n",
      "\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 1057 samples (6.606 s)\n",
      "\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 1057 samples (6.606 s)\n",
      "\n",
      "Used Annotations descriptions: [np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "45 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 45 events and 801 original time points ...\n",
      "0 bad epochs dropped\n",
      "Filtering raw data in 3 contiguous segments\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "Filtering raw data in 3 contiguous segments\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 1057 samples (6.606 s)\n",
      "\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 1057 samples (6.606 s)\n",
      "\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 1057 samples (6.606 s)\n",
      "\n",
      "Used Annotations descriptions: [np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "24 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 24 events and 801 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "epochs_lr = process_and_epoch(raw_lr, event_id={'left_fist': 1, 'right_fist': 2})\n",
    "epochs_feet = process_and_epoch(raw_feet, event_id={'feet': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cde194fc-c5d5-4e6a-8303-0e42b04fb04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "69 matching events found\n",
      "No baseline correction applied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1s/bkqkh8453p79rr15mcq_bm4c0000gp/T/ipykernel_55915/4130775407.py:2: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  epochs = mne.concatenate_epochs([epochs_lr, epochs_feet])\n"
     ]
    }
   ],
   "source": [
    "# Combine all processed epochs from all tasks into a single object for the classifier.\n",
    "epochs = mne.concatenate_epochs([epochs_lr, epochs_feet])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287d5df7-f526-4576-b9f8-f190c7b183c9",
   "metadata": {},
   "source": [
    "## 5. Feature and Label Preparation\n",
    "\n",
    "We extract the final processed data and corresponding labels from the `Epochs` object. This prepares them for direct use with scikit-learn's machine learning models. The data is now a 3D NumPy array (`trials x channels x timepoints`), and the labels are a 1D vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "204da96a-d60b-4f64-b359-afef70774e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = epochs.get_data() # The data is a 3D numpy array: (n_epochs, n_channels, n_times).\n",
    "labels = epochs.events[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08f189c-fb32-491f-b3d6-178324f622ac",
   "metadata": {},
   "source": [
    "## 6. Machine Learning Pipeline: CSP + LDA\n",
    "\n",
    "To classify the high-dimensional EEG epochs, we build a pipeline that first extracts meaningful features and then uses a simple classifier.\n",
    "\n",
    "### Common Spatial Patterns (CSP)\n",
    "CSP is a feature extraction algorithm that finds spatial filters $W$ to maximize the variance for one class while minimizing it for another. This is ideal for discriminating between motor imagery tasks. The optimization problem it solves is maximizing the Rayleigh quotient:\n",
    "\n",
    "$$J(w) = \\frac{w^T \\Sigma_1 w}{w^T \\Sigma_2 w}$$\n",
    "\n",
    "- $w$ is the spatial filter (a set of weights for each channel).\n",
    "- $\\Sigma_1$ is the covariance matrix of the EEG data for the first class (e.g., left fist).\n",
    "- $\\Sigma_2$ is the covariance matrix of the EEG data for the second class (e.g., right fist).\n",
    "\n",
    "### Linear Discriminant Analysis (LDA)\n",
    "LDA is a linear classifier that projects the features from CSP onto a line to maximize the separation between the classes. The decision function for a new sample $x$ is:\n",
    "\n",
    "$$y(x) = w^T x + w_0$$\n",
    "\n",
    "### One-vs-Rest (OvR) Strategy\n",
    "Since CSP and LDA are inherently binary, we use the One-vs-Rest (OvR) strategy to handle our 3-class problem. It trains $K$ separate classifiers (where $K=3$ here). For a new sample $x$, the final prediction is the class $k$ whose classifier reports the highest confidence score:\n",
    "\n",
    "$$\\text{class} = \\arg\\max_{k \\in \\{1, ..., K\\}} f_k(x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad9e8a2a-cb8a-41bf-9f4e-32425544e1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "csp = CSP(n_components=4, reg=None, log=True) # n_components=4 means we are extracting the 4 most discriminative spatial patterns.\n",
    "lda = LDA()\n",
    "ovr_pipeline = OneVsRestClassifier(Pipeline([('CSP', csp), ('LDA', lda)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cde53d6-39c4-439e-9a84-1be3d67361bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.00036 (2.2e-16 eps * 64 dim * 2.6e+10  max singular value)\n",
      "    Estimated rank (data): 64\n",
      "    data: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating class=0 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=1 covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.00037 (2.2e-16 eps * 64 dim * 2.6e+10  max singular value)\n",
      "    Estimated rank (data): 64\n",
      "    data: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating class=0 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=1 covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.00037 (2.2e-16 eps * 64 dim * 2.6e+10  max singular value)\n",
      "    Estimated rank (data): 64\n",
      "    data: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating class=0 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=1 covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.00037 (2.2e-16 eps * 64 dim * 2.6e+10  max singular value)\n",
      "    Estimated rank (data): 64\n",
      "    data: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating class=0 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=1 covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 0.00037 (2.2e-16 eps * 64 dim * 2.6e+10  max singular value)\n",
      "    Estimated rank (data): 64\n",
      "    data: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating class=0 covariance using EMPIRICAL\n",
      "Done.\n",
      "Estimating class=1 covariance using EMPIRICAL\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Set up the cross-validation strategy. StratifiedKFold ensures each fold\n",
    "# has a representative balance of all three classes.\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(ovr_pipeline, data, labels, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd0c8e39-dd34-40bf-b266-781b076a3513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3-Class Cross-Validation Accuracy ---\n",
      "Scores for each fold: [0.57142857 0.35714286 0.64285714 0.64285714 0.92307692]\n",
      "Mean Accuracy: 0.6275\n",
      "Standard Deviation: 0.1811\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 3-Class Cross-Validation Accuracy ---\")\n",
    "print(f\"Scores for each fold: {scores}\")\n",
    "print(f\"Mean Accuracy: {np.mean(scores):.4f}\")\n",
    "print(f\"Standard Deviation: {np.std(scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34700805-988e-4cc7-a5f5-45e9a26a44db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
